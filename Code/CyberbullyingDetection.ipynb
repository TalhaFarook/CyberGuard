{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22ad64de",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "**Step 1:** Importing All Libraries<br>\n",
    "In this step, we will be importing all the libraries necessary for this project.\n",
    "--------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fe52612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import requests as rq\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#!pip install wordninja\n",
    "import wordninja\n",
    "\n",
    "#!pip install spacy\n",
    "import spacy\n",
    "#spacy.cli.download(\"en_core_web_sm\")\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.download('punkt')\n",
    "\n",
    "#!pip install contractions\n",
    "import contractions\n",
    "\n",
    "#!pip install vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1e2bb4",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "**Step 2:** Importing Dataset<br>\n",
    "In this step, we will import the dataset that we will use in this project.\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ee2494c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Watching gaters confuse @ggautoblocker and @th...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Xanthe_Cat nice to know I made him mad, then ðŸ˜œ</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just hopped on the struggle bus. Gonna be a lo...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aw there's nothing to cry about Lynn xx #MKR</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They are literally going thru a laundry list o...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweets_text              type\n",
       "0  Watching gaters confuse @ggautoblocker and @th...  notcyberbullying\n",
       "1    @Xanthe_Cat nice to know I made him mad, then ðŸ˜œ  notcyberbullying\n",
       "2  Just hopped on the struggle bus. Gonna be a lo...  notcyberbullying\n",
       "3       Aw there's nothing to cry about Lynn xx #MKR  notcyberbullying\n",
       "4  They are literally going thru a laundry list o...  notcyberbullying"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\USER\\Documents\\FinalYearProject\\NotBullyingData.csv\")\n",
    "classifyData = pd.read_csv(r\"C:\\Users\\USER\\Documents\\FinalYearProject\\trainingData1.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fdc162",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "**Step 3:** Data Preprocessing<br>\n",
    "In this step, we will perform preprocessing and cleaning of data.\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551850d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function will return words from the link provided as a parameter\n",
    "def returnWords(link):\n",
    "    raw = rq.get(link).content\n",
    "    listWords = list(raw.decode().splitlines())\n",
    "    \n",
    "    return listWords\n",
    "\n",
    "#This function will convert a list to a string\n",
    "def string(data):\n",
    "    string = ' '\n",
    "    \n",
    "    return (string.join(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "756fad44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watching gaters confuse @ggautoblocker and @th...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@xanthe_cat nice to know i made him mad, then ðŸ˜œ</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just hopped on the struggle bus. gonna be a lo...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aw there's nothing to cry about lynn xx #mkr</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they are literally going thru a laundry list o...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweets_text              type\n",
       "0  watching gaters confuse @ggautoblocker and @th...  notcyberbullying\n",
       "1    @xanthe_cat nice to know i made him mad, then ðŸ˜œ  notcyberbullying\n",
       "2  just hopped on the struggle bus. gonna be a lo...  notcyberbullying\n",
       "3       aw there's nothing to cry about lynn xx #mkr  notcyberbullying\n",
       "4  they are literally going thru a laundry list o...  notcyberbullying"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lowercasing all the tweets in the dataframe\n",
    "data['tweets_text'] = data['tweets_text'].str.lower()\n",
    "classifyData['tweets_text'] = classifyData['tweets_text'].str.lower()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b711deb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watching gaters confuse ggautoblocker and theb...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xanthe cat nice to know i made him mad then</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just hopped on the struggle bus gonna be a lon...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aw theres nothing to cry about lynn xx mkr</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they are literally going thru a laundry list o...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweets_text              type\n",
       "0  watching gaters confuse ggautoblocker and theb...  notcyberbullying\n",
       "1       xanthe cat nice to know i made him mad then   notcyberbullying\n",
       "2  just hopped on the struggle bus gonna be a lon...  notcyberbullying\n",
       "3         aw theres nothing to cry about lynn xx mkr  notcyberbullying\n",
       "4  they are literally going thru a laundry list o...  notcyberbullying"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regular expressions are used to clean data like @ usernames, links, retweet (RT), digits, any special characters \n",
    "temp = ''\n",
    "for index, row in enumerate(data['tweets_text']):\n",
    "    temp = re.sub(r'(\\brt)|(http\\S+)|(\\d+)|(&(gt;)+)|(&(lt;)+)|(&(amp;)+)|([^\\w\\s])', '', str(row))\n",
    "    temp = re.sub('(\\'| )|(\\\"| )|(_)', ' ', temp)\n",
    "    data['tweets_text'][index] = temp\n",
    "    \n",
    "temp = ''\n",
    "for index, row in enumerate(classifyData['tweets_text']):\n",
    "    temp = re.sub(r'(\\brt)|(http\\S+)|(\\d+)|(&(gt;)+)|(&(lt;)+)|(&(amp;)+)|([^\\w\\s])', '', str(row))\n",
    "    temp = re.sub('(\\'| )|(\\\"| )|(_)', ' ', temp)\n",
    "    classifyData['tweets_text'][index] = temp\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d65afa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watching gaters confuse ggautoblocker and theb...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xanthe cat nice to know i made him mad then</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just hopped on the struggle bus going to be a ...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aw there is nothing to cry about lynn xx mkr</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they are literally going thru a laundry list o...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweets_text              type\n",
       "0  watching gaters confuse ggautoblocker and theb...  notcyberbullying\n",
       "1        xanthe cat nice to know i made him mad then  notcyberbullying\n",
       "2  just hopped on the struggle bus going to be a ...  notcyberbullying\n",
       "3       aw there is nothing to cry about lynn xx mkr  notcyberbullying\n",
       "4  they are literally going thru a laundry list o...  notcyberbullying"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Contractions are expanded in this section (ex. aren't -> are not, arent -> are not)\n",
    "for index, row in enumerate(data['tweets_text']):\n",
    "    temp = []\n",
    "    for word in row.split():\n",
    "        temp.append(contractions.fix(word))\n",
    "    data['tweets_text'][index] = string(temp)\n",
    "    \n",
    "for index, row in enumerate(classifyData['tweets_text']):\n",
    "    temp = []\n",
    "    for word in row.split():\n",
    "        temp.append(contractions.fix(word))\n",
    "    classifyData['tweets_text'][index] = string(temp)\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d557df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watching gaters confuse ggautoblocker and theb...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xanthe cat nice to know i made him mad then</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just hopped on the struggle bus going to be a ...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aw there is nothing to cry about lynn xx mkr</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they are literally going thru a laundry list o...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweets_text              type\n",
       "0  watching gaters confuse ggautoblocker and theb...  notcyberbullying\n",
       "1        xanthe cat nice to know i made him mad then  notcyberbullying\n",
       "2  just hopped on the struggle bus going to be a ...  notcyberbullying\n",
       "3       aw there is nothing to cry about lynn xx mkr  notcyberbullying\n",
       "4  they are literally going thru a laundry list o...  notcyberbullying"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This dataframe contains all the slangs and their respective abbreviations (ex. hml -> hate my life)\n",
    "slangWords = pd.read_csv(r\"C:\\Users\\USER\\Documents\\FinalYearProject\\SlangUpdated.txt\")\n",
    "\n",
    "for num, row in enumerate(data['tweets_text']):\n",
    "    temp = []\n",
    "    for word in row.split():\n",
    "        found = 0\n",
    "        if (len(word)<6 and len(word)>2): \n",
    "            for index, slang in enumerate(slangWords['slang']):\n",
    "                if (slang == word):\n",
    "                    temp.append(slangWords['word'][index])\n",
    "                    found = 1\n",
    "        if (found != 1):\n",
    "            temp.append(word)\n",
    "    data['tweets_text'][num] = string(temp)\n",
    "    \n",
    "for num, row in enumerate(classifyData['tweets_text']):\n",
    "    temp = []\n",
    "    for word in row.split():\n",
    "        found = 0\n",
    "        if (len(word)<6 and len(word)>2): \n",
    "            for index, slang in enumerate(slangWords['slang']):\n",
    "                if (slang == word):\n",
    "                    temp.append(slangWords['word'][index])\n",
    "                    found = 1\n",
    "        if (found != 1):\n",
    "            temp.append(word)\n",
    "    classifyData['tweets_text'][num] = string(temp)\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a39baee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_text</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watching gate rs confuse gg auto blocker and t...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x an the cat nice to know i made him mad then</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just hopped on the struggle bus going to be a ...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aw there is nothing to cry about lynn xx mkr</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they are literally going thru a laundry list o...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweets_text              type\n",
       "0  watching gate rs confuse gg auto blocker and t...  notcyberbullying\n",
       "1      x an the cat nice to know i made him mad then  notcyberbullying\n",
       "2  just hopped on the struggle bus going to be a ...  notcyberbullying\n",
       "3       aw there is nothing to cry about lynn xx mkr  notcyberbullying\n",
       "4  they are literally going thru a laundry list o...  notcyberbullying"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This section expands all munched words (ex. weshouldleave -> we should leave)\n",
    "for index, row in enumerate(data['tweets_text']):\n",
    "    temp = []\n",
    "    for word in row.split():\n",
    "        if (len(word)>4):\n",
    "            unmunched = wordninja.split(word)\n",
    "            temp.append(string(unmunched))\n",
    "        else:\n",
    "            temp.append(word)\n",
    "    data['tweets_text'][index] = string(temp)\n",
    "    \n",
    "for index, row in enumerate(classifyData['tweets_text']):\n",
    "    temp = []\n",
    "    for word in row.split():\n",
    "        if (len(word)>4):\n",
    "            unmunched = wordninja.split(word)\n",
    "            temp.append(string(unmunched))\n",
    "        else:\n",
    "            temp.append(word)\n",
    "    classifyData['tweets_text'][index] = string(temp)\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff5791b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_text</th>\n",
       "      <th>type</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watching gate rs confuse gg auto blocker and t...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[watching, gate, rs, confuse, gg, auto, blocke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x an the cat nice to know i made him mad then</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[x, an, the, cat, nice, to, know, i, made, him...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just hopped on the struggle bus going to be a ...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[just, hopped, on, the, struggle, bus, going, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aw there is nothing to cry about lynn xx mkr</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[aw, there, is, nothing, to, cry, about, lynn,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they are literally going thru a laundry list o...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[they, are, literally, going, thru, a, laundry...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweets_text              type  \\\n",
       "0  watching gate rs confuse gg auto blocker and t...  notcyberbullying   \n",
       "1      x an the cat nice to know i made him mad then  notcyberbullying   \n",
       "2  just hopped on the struggle bus going to be a ...  notcyberbullying   \n",
       "3       aw there is nothing to cry about lynn xx mkr  notcyberbullying   \n",
       "4  they are literally going thru a laundry list o...  notcyberbullying   \n",
       "\n",
       "                                              tokens  \n",
       "0  [watching, gate, rs, confuse, gg, auto, blocke...  \n",
       "1  [x, an, the, cat, nice, to, know, i, made, him...  \n",
       "2  [just, hopped, on, the, struggle, bus, going, ...  \n",
       "3  [aw, there, is, nothing, to, cry, about, lynn,...  \n",
       "4  [they, are, literally, going, thru, a, laundry...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Scan entity names in the data to create tokens according to it (ex. 'donald trump' as a single token)\n",
    "# entityRecognition = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# entityScanned = []\n",
    "# for row in data['tweets_text']:\n",
    "#     entityScanned.append(entityRecognition(row))\n",
    "\n",
    "# entity, singleEntity, tokens = [], [], []\n",
    "# for row in entityScanned:\n",
    "#     temp = []\n",
    "#     for word in row:\n",
    "#         if word.ent_iob_ == 'B': #B shows the start of the entity\n",
    "#             singleEntity.append(str(word))\n",
    "#         elif word.ent_iob_ == 'I': #I shows that it is inside an entity\n",
    "#             singleEntity.append(str(word))\n",
    "#         elif word.ent_iob_ == 'O': #O shows that it is outside an entity\n",
    "#             entity.append(' '.join(singleEntity))\n",
    "#             if (len(singleEntity)>0):\n",
    "#                 temp.append(' '.join(singleEntity))\n",
    "#             else:\n",
    "#                 temp.append(str(word))\n",
    "#             if (len(singleEntity) > 1):\n",
    "#                 print(singleEntity)\n",
    "#             singleEntity = []\n",
    "#     tokens.append(temp)\n",
    "\n",
    "tokens = []\n",
    "for row in data['tweets_text']:\n",
    "    tokens.append(word_tokenize(row))\n",
    "\n",
    "data['tokens'] = tokens\n",
    "\n",
    "tokens = []\n",
    "for row in classifyData['tweets_text']:\n",
    "    tokens.append(word_tokenize(row))\n",
    "        \n",
    "classifyData['tokens'] = tokens\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a92292",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "**Step 4:** Data Transformation<br>\n",
    "In this step, we are converting data from textual to numeric format to feed to our model.\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e346f22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_text</th>\n",
       "      <th>type</th>\n",
       "      <th>tokens</th>\n",
       "      <th>total words</th>\n",
       "      <th>offensive words</th>\n",
       "      <th>severity words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watching gate rs confuse gg auto blocker and t...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[watching, gate, rs, confuse, gg, auto, blocke...</td>\n",
       "      <td>21</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x an the cat nice to know i made him mad then</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[x, an, the, cat, nice, to, know, i, made, him...</td>\n",
       "      <td>12</td>\n",
       "      <td>[mad]</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just hopped on the struggle bus going to be a ...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[just, hopped, on, the, struggle, bus, going, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aw there is nothing to cry about lynn xx mkr</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[aw, there, is, nothing, to, cry, about, lynn,...</td>\n",
       "      <td>10</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they are literally going thru a laundry list o...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[they, are, literally, going, thru, a, laundry...</td>\n",
       "      <td>15</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweets_text              type  \\\n",
       "0  watching gate rs confuse gg auto blocker and t...  notcyberbullying   \n",
       "1      x an the cat nice to know i made him mad then  notcyberbullying   \n",
       "2  just hopped on the struggle bus going to be a ...  notcyberbullying   \n",
       "3       aw there is nothing to cry about lynn xx mkr  notcyberbullying   \n",
       "4  they are literally going thru a laundry list o...  notcyberbullying   \n",
       "\n",
       "                                              tokens  total words  \\\n",
       "0  [watching, gate, rs, confuse, gg, auto, blocke...           21   \n",
       "1  [x, an, the, cat, nice, to, know, i, made, him...           12   \n",
       "2  [just, hopped, on, the, struggle, bus, going, ...           14   \n",
       "3  [aw, there, is, nothing, to, cry, about, lynn,...           10   \n",
       "4  [they, are, literally, going, thru, a, laundry...           15   \n",
       "\n",
       "  offensive words severity words  \n",
       "0              []             []  \n",
       "1           [mad]            [2]  \n",
       "2              []             []  \n",
       "3              []             []  \n",
       "4              []             []  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counting number of words, offensive words and the severity of the offensive words.\n",
    "offenseWords = pd.read_csv(r\"C:\\Users\\USER\\Documents\\FinalYearProject\\OffensiveWithSeverity.txt\")\n",
    "negationWords = pd.read_csv(r\"C:\\Users\\USER\\Documents\\FinalYearProject\\Negation.txt\")\n",
    "\n",
    "totalWords, offensiveWords, severityWords = [], [], []\n",
    "\n",
    "for row in data['tokens']:\n",
    "    words, temp1, temp2 = 0, [], []\n",
    "    for index1, token in enumerate(row):\n",
    "        words += 1\n",
    "        for index2, offensive in enumerate(offenseWords['word']):\n",
    "            if (token == offensive):\n",
    "                negation = 0\n",
    "                for negation in negationWords['word']: #Checking for negation words at most 2 words before the negative word \n",
    "                    if (row[index1-1] == negation or row[index1-2] == negation):\n",
    "                        negation = 1\n",
    "                        break\n",
    "                if (negation != 1):\n",
    "                    temp1.append(token)\n",
    "                    temp2.append(offenseWords['severity'][index2])\n",
    "    totalWords.append(words)\n",
    "    offensiveWords.append(temp1)\n",
    "    severityWords.append(temp2)\n",
    "\n",
    "data['total words'] = totalWords\n",
    "data['offensive words'] = offensiveWords\n",
    "data['severity words'] = severityWords\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1565b129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_text</th>\n",
       "      <th>type</th>\n",
       "      <th>tokens</th>\n",
       "      <th>total words</th>\n",
       "      <th>offensive words</th>\n",
       "      <th>severity words</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watching gate rs confuse gg auto blocker and t...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[watching, gate, rs, confuse, gg, auto, blocke...</td>\n",
       "      <td>21</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x an the cat nice to know i made him mad then</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[x, an, the, cat, nice, to, know, i, made, him...</td>\n",
       "      <td>12</td>\n",
       "      <td>[mad]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just hopped on the struggle bus going to be a ...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[just, hopped, on, the, struggle, bus, going, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aw there is nothing to cry about lynn xx mkr</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[aw, there, is, nothing, to, cry, about, lynn,...</td>\n",
       "      <td>10</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they are literally going thru a laundry list o...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[they, are, literally, going, thru, a, laundry...</td>\n",
       "      <td>15</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweets_text              type  \\\n",
       "0  watching gate rs confuse gg auto blocker and t...  notcyberbullying   \n",
       "1      x an the cat nice to know i made him mad then  notcyberbullying   \n",
       "2  just hopped on the struggle bus going to be a ...  notcyberbullying   \n",
       "3       aw there is nothing to cry about lynn xx mkr  notcyberbullying   \n",
       "4  they are literally going thru a laundry list o...  notcyberbullying   \n",
       "\n",
       "                                              tokens  total words  \\\n",
       "0  [watching, gate, rs, confuse, gg, auto, blocke...           21   \n",
       "1  [x, an, the, cat, nice, to, know, i, made, him...           12   \n",
       "2  [just, hopped, on, the, struggle, bus, going, ...           14   \n",
       "3  [aw, there, is, nothing, to, cry, about, lynn,...           10   \n",
       "4  [they, are, literally, going, thru, a, laundry...           15   \n",
       "\n",
       "  offensive words severity words   density  \n",
       "0              []             []  0.000000  \n",
       "1           [mad]            [2]  0.083333  \n",
       "2              []             []  0.000000  \n",
       "3              []             []  0.000000  \n",
       "4              []             []  0.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Features for the model to predict whether it is offensive or not.\n",
    "#Density of offensive words in a sentence.\n",
    "density = []\n",
    "    \n",
    "for total, offensive in zip(data['total words'], data['offensive words']):\n",
    "    density.append(len(offensive) / total)\n",
    "\n",
    "data['density'] = density\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9312674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_text</th>\n",
       "      <th>type</th>\n",
       "      <th>tokens</th>\n",
       "      <th>total words</th>\n",
       "      <th>offensive words</th>\n",
       "      <th>severity words</th>\n",
       "      <th>density</th>\n",
       "      <th>sentiment analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watching gate rs confuse gg auto blocker and t...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[watching, gate, rs, confuse, gg, auto, blocke...</td>\n",
       "      <td>21</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.3818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x an the cat nice to know i made him mad then</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[x, an, the, cat, nice, to, know, i, made, him...</td>\n",
       "      <td>12</td>\n",
       "      <td>[mad]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-0.1027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just hopped on the struggle bus going to be a ...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[just, hopped, on, the, struggle, bus, going, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.3182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aw there is nothing to cry about lynn xx mkr</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[aw, there, is, nothing, to, cry, about, lynn,...</td>\n",
       "      <td>10</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they are literally going thru a laundry list o...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[they, are, literally, going, thru, a, laundry...</td>\n",
       "      <td>15</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweets_text              type  \\\n",
       "0  watching gate rs confuse gg auto blocker and t...  notcyberbullying   \n",
       "1      x an the cat nice to know i made him mad then  notcyberbullying   \n",
       "2  just hopped on the struggle bus going to be a ...  notcyberbullying   \n",
       "3       aw there is nothing to cry about lynn xx mkr  notcyberbullying   \n",
       "4  they are literally going thru a laundry list o...  notcyberbullying   \n",
       "\n",
       "                                              tokens  total words  \\\n",
       "0  [watching, gate, rs, confuse, gg, auto, blocke...           21   \n",
       "1  [x, an, the, cat, nice, to, know, i, made, him...           12   \n",
       "2  [just, hopped, on, the, struggle, bus, going, ...           14   \n",
       "3  [aw, there, is, nothing, to, cry, about, lynn,...           10   \n",
       "4  [they, are, literally, going, thru, a, laundry...           15   \n",
       "\n",
       "  offensive words severity words   density  sentiment analysis  \n",
       "0              []             []  0.000000             -0.3818  \n",
       "1           [mad]            [2]  0.083333             -0.1027  \n",
       "2              []             []  0.000000             -0.3182  \n",
       "3              []             []  0.000000              0.3724  \n",
       "4              []             []  0.000000              0.0000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sentimental analysis to determine polarity of data. \n",
    "#Compound range from -1 to +1 depending on whether it is negative or positive.\n",
    "\n",
    "compound = []\n",
    "for row in data['tweets_text']:\n",
    "    polarity = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    "    compound.append(polarity[\"compound\"])\n",
    "\n",
    "data['sentiment analysis'] = compound\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cdbb34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_text</th>\n",
       "      <th>type</th>\n",
       "      <th>tokens</th>\n",
       "      <th>total words</th>\n",
       "      <th>offensive words</th>\n",
       "      <th>severity words</th>\n",
       "      <th>density</th>\n",
       "      <th>sentiment analysis</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>watching gate rs confuse gg auto blocker and t...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[watching, gate, rs, confuse, gg, auto, blocke...</td>\n",
       "      <td>21</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.3818</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x an the cat nice to know i made him mad then</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[x, an, the, cat, nice, to, know, i, made, him...</td>\n",
       "      <td>12</td>\n",
       "      <td>[mad]</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>-0.1027</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>just hopped on the struggle bus going to be a ...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[just, hopped, on, the, struggle, bus, going, ...</td>\n",
       "      <td>14</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.3182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aw there is nothing to cry about lynn xx mkr</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[aw, there, is, nothing, to, cry, about, lynn,...</td>\n",
       "      <td>10</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3724</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>they are literally going thru a laundry list o...</td>\n",
       "      <td>notcyberbullying</td>\n",
       "      <td>[they, are, literally, going, thru, a, laundry...</td>\n",
       "      <td>15</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweets_text              type  \\\n",
       "0  watching gate rs confuse gg auto blocker and t...  notcyberbullying   \n",
       "1      x an the cat nice to know i made him mad then  notcyberbullying   \n",
       "2  just hopped on the struggle bus going to be a ...  notcyberbullying   \n",
       "3       aw there is nothing to cry about lynn xx mkr  notcyberbullying   \n",
       "4  they are literally going thru a laundry list o...  notcyberbullying   \n",
       "\n",
       "                                              tokens  total words  \\\n",
       "0  [watching, gate, rs, confuse, gg, auto, blocke...           21   \n",
       "1  [x, an, the, cat, nice, to, know, i, made, him...           12   \n",
       "2  [just, hopped, on, the, struggle, bus, going, ...           14   \n",
       "3  [aw, there, is, nothing, to, cry, about, lynn,...           10   \n",
       "4  [they, are, literally, going, thru, a, laundry...           15   \n",
       "\n",
       "  offensive words severity words   density  sentiment analysis  severity  \n",
       "0              []             []  0.000000             -0.3818       0.0  \n",
       "1           [mad]            [2]  0.083333             -0.1027       2.0  \n",
       "2              []             []  0.000000             -0.3182       0.0  \n",
       "3              []             []  0.000000              0.3724       0.0  \n",
       "4              []             []  0.000000              0.0000       0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weighted mean of severity words\n",
    "\n",
    "severity, weights = [], [1, 2, 3, 4, 5]\n",
    "for severe in data['severity words']:\n",
    "    count, product = [0, 0, 0, 0, 0], []\n",
    "    for num in severe:\n",
    "        if (num == 1):\n",
    "            count[0] += 1\n",
    "        elif (num == 2):\n",
    "            count[1] += 1 \n",
    "        elif (num == 3):\n",
    "            count[2] += 1\n",
    "        elif (num == 4):\n",
    "            count[3] += 1 \n",
    "        elif (num == 5):\n",
    "            count[4] += 1       \n",
    "    for num1, num2 in zip(count, weights):\n",
    "        product.append(num1 * num2)\n",
    "    \n",
    "    totalProduct = sum(product)\n",
    "    totalCount = sum(count)\n",
    "    \n",
    "    if (totalCount == 0):\n",
    "        severity.append(0)\n",
    "    else:\n",
    "        severity.append(totalProduct / totalCount)\n",
    "        \n",
    "data['severity'] = severity\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dfb2d7",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "**Step 5:** Machine Learning<br>\n",
    "In this step, we are training and then testing our model.\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79879ab",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "**Part A:** \n",
    "In this part, we will train our model to predict whether a tweet is offensive or not.\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c724295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionDataM1 = data[['density', 'severity', 'sentiment analysis']].copy()\n",
    "targetM1 = data['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1be85c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:00<00:00, 30.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  Balanced Accuracy ROC AUC  F1 Score  \\\n",
      "Model                                                                          \n",
      "SVC                                0.88               0.88    None      0.88   \n",
      "NuSVC                              0.88               0.88    None      0.88   \n",
      "AdaBoostClassifier                 0.84               0.84    None      0.84   \n",
      "CalibratedClassifierCV             0.84               0.84    None      0.84   \n",
      "LogisticRegression                 0.84               0.84    None      0.84   \n",
      "LinearDiscriminantAnalysis         0.83               0.83    None      0.83   \n",
      "RidgeClassifierCV                  0.83               0.83    None      0.83   \n",
      "RidgeClassifier                    0.83               0.83    None      0.83   \n",
      "NearestCentroid                    0.83               0.83    None      0.83   \n",
      "LinearSVC                          0.83               0.83    None      0.83   \n",
      "PassiveAggressiveClassifier        0.81               0.81    None      0.81   \n",
      "LGBMClassifier                     0.81               0.81    None      0.81   \n",
      "LabelPropagation                   0.80               0.80    None      0.80   \n",
      "LabelSpreading                     0.80               0.80    None      0.80   \n",
      "KNeighborsClassifier               0.80               0.80    None      0.80   \n",
      "BernoulliNB                        0.80               0.80    None      0.80   \n",
      "QuadraticDiscriminantAnalysis      0.79               0.79    None      0.79   \n",
      "GaussianNB                         0.78               0.78    None      0.78   \n",
      "RandomForestClassifier             0.78               0.78    None      0.78   \n",
      "SGDClassifier                      0.78               0.78    None      0.78   \n",
      "BaggingClassifier                  0.77               0.77    None      0.77   \n",
      "ExtraTreesClassifier               0.75               0.75    None      0.75   \n",
      "Perceptron                         0.74               0.74    None      0.72   \n",
      "DecisionTreeClassifier             0.74               0.74    None      0.74   \n",
      "ExtraTreeClassifier                0.73               0.73    None      0.73   \n",
      "DummyClassifier                    0.50               0.50    None      0.33   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "SVC                                  0.04  \n",
      "NuSVC                                0.03  \n",
      "AdaBoostClassifier                   0.10  \n",
      "CalibratedClassifierCV               0.11  \n",
      "LogisticRegression                   0.02  \n",
      "LinearDiscriminantAnalysis           0.02  \n",
      "RidgeClassifierCV                    0.01  \n",
      "RidgeClassifier                      0.01  \n",
      "NearestCentroid                      0.00  \n",
      "LinearSVC                            0.02  \n",
      "PassiveAggressiveClassifier          0.02  \n",
      "LGBMClassifier                       0.09  \n",
      "LabelPropagation                     0.02  \n",
      "LabelSpreading                       0.02  \n",
      "KNeighborsClassifier                 0.02  \n",
      "BernoulliNB                          0.02  \n",
      "QuadraticDiscriminantAnalysis        0.00  \n",
      "GaussianNB                           0.01  \n",
      "RandomForestClassifier               0.17  \n",
      "SGDClassifier                        0.01  \n",
      "BaggingClassifier                    0.03  \n",
      "ExtraTreesClassifier                 0.12  \n",
      "Perceptron                           0.02  \n",
      "DecisionTreeClassifier               0.01  \n",
      "ExtraTreeClassifier                  0.02  \n",
      "DummyClassifier                      0.01  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!pip install lazypredict\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "trainData, testData, trainTarget, testTarget = train_test_split(predictionDataM1, targetM1, test_size = 0.15, random_state = 30, stratify = targetM1)\n",
    "\n",
    "models, predictions = clf.fit(trainData, testData, trainTarget, testTarget)\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec83959",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "**Part B:** \n",
    "In this part, we will train our model to predict whether the offensive tweet is related to religion, age, gender or race/ethnicity.\n",
    "-------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "359de272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_text</th>\n",
       "      <th>type</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ethnicity and race</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>del en as dictator paul makes gay rape jokes a...</td>\n",
       "      <td>gender</td>\n",
       "      <td>[del, en, as, dictator, paul, makes, gay, rape...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arabs and muslims do not supporting you do not...</td>\n",
       "      <td>religion</td>\n",
       "      <td>[arabs, and, muslims, do, not, supporting, you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is not this a trope in like every teen movie e...</td>\n",
       "      <td>gender</td>\n",
       "      <td>[is, not, this, a, trope, in, like, every, tee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dumb goth fuck you nigger blocked</td>\n",
       "      <td>ethnicityandrace</td>\n",
       "      <td>[dumb, goth, fuck, you, nigger, blocked]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nigga i am laying down try na sleep get to bed...</td>\n",
       "      <td>ethnicityandrace</td>\n",
       "      <td>[nigga, i, am, laying, down, try, na, sleep, g...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweets_text              type  \\\n",
       "0  del en as dictator paul makes gay rape jokes a...            gender   \n",
       "1  arabs and muslims do not supporting you do not...          religion   \n",
       "2  is not this a trope in like every teen movie e...            gender   \n",
       "3                  dumb goth fuck you nigger blocked  ethnicityandrace   \n",
       "4  nigga i am laying down try na sleep get to bed...  ethnicityandrace   \n",
       "\n",
       "                                              tokens  ethnicity and race  \n",
       "0  [del, en, as, dictator, paul, makes, gay, rape...                   0  \n",
       "1  [arabs, and, muslims, do, not, supporting, you...                   0  \n",
       "2  [is, not, this, a, trope, in, like, every, tee...                   0  \n",
       "3           [dumb, goth, fuck, you, nigger, blocked]                   1  \n",
       "4  [nigga, i, am, laying, down, try, na, sleep, g...                   3  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethnicityAndRaceGlossary = pd.read_csv(r\"C:\\Users\\USER\\Documents\\FinalYearProject\\EthnicityAndRaceGlossary.txt\")\n",
    "\n",
    "isEthnicityAndRace = []\n",
    "for row in classifyData['tokens']:\n",
    "    temp = 0\n",
    "    for token in row:\n",
    "        for glossary in ethnicityAndRaceGlossary['word']:\n",
    "            if (token == glossary):\n",
    "                temp += 1\n",
    "                break\n",
    "    isEthnicityAndRace.append(temp)\n",
    "\n",
    "classifyData['ethnicity and race'] = isEthnicityAndRace\n",
    "classifyData.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c60eeec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_text</th>\n",
       "      <th>type</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ethnicity and race</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>del en as dictator paul makes gay rape jokes a...</td>\n",
       "      <td>gender</td>\n",
       "      <td>[del, en, as, dictator, paul, makes, gay, rape...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arabs and muslims do not supporting you do not...</td>\n",
       "      <td>religion</td>\n",
       "      <td>[arabs, and, muslims, do, not, supporting, you...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is not this a trope in like every teen movie e...</td>\n",
       "      <td>gender</td>\n",
       "      <td>[is, not, this, a, trope, in, like, every, tee...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dumb goth fuck you nigger blocked</td>\n",
       "      <td>ethnicityandrace</td>\n",
       "      <td>[dumb, goth, fuck, you, nigger, blocked]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nigga i am laying down try na sleep get to bed...</td>\n",
       "      <td>ethnicityandrace</td>\n",
       "      <td>[nigga, i, am, laying, down, try, na, sleep, g...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweets_text              type  \\\n",
       "0  del en as dictator paul makes gay rape jokes a...            gender   \n",
       "1  arabs and muslims do not supporting you do not...          religion   \n",
       "2  is not this a trope in like every teen movie e...            gender   \n",
       "3                  dumb goth fuck you nigger blocked  ethnicityandrace   \n",
       "4  nigga i am laying down try na sleep get to bed...  ethnicityandrace   \n",
       "\n",
       "                                              tokens  ethnicity and race  age  \n",
       "0  [del, en, as, dictator, paul, makes, gay, rape...                   0    0  \n",
       "1  [arabs, and, muslims, do, not, supporting, you...                   0    1  \n",
       "2  [is, not, this, a, trope, in, like, every, tee...                   0    3  \n",
       "3           [dumb, goth, fuck, you, nigger, blocked]                   1    1  \n",
       "4  [nigga, i, am, laying, down, try, na, sleep, g...                   3    3  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ageDataGlossary = pd.read_csv(r\"C:\\Users\\USER\\Documents\\FinalYearProject\\AgeGlossary.txt\")\n",
    "\n",
    "isAge = []\n",
    "for row in classifyData['tokens']:\n",
    "    temp = 0\n",
    "    for token in row:\n",
    "        for glossary in ageDataGlossary['word']:\n",
    "            if (token == glossary):\n",
    "                temp += 1\n",
    "                break\n",
    "    isAge.append(temp)\n",
    "\n",
    "classifyData['age'] = isAge\n",
    "classifyData.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc9d7d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_text</th>\n",
       "      <th>type</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ethnicity and race</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>del en as dictator paul makes gay rape jokes a...</td>\n",
       "      <td>gender</td>\n",
       "      <td>[del, en, as, dictator, paul, makes, gay, rape...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arabs and muslims do not supporting you do not...</td>\n",
       "      <td>religion</td>\n",
       "      <td>[arabs, and, muslims, do, not, supporting, you...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is not this a trope in like every teen movie e...</td>\n",
       "      <td>gender</td>\n",
       "      <td>[is, not, this, a, trope, in, like, every, tee...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dumb goth fuck you nigger blocked</td>\n",
       "      <td>ethnicityandrace</td>\n",
       "      <td>[dumb, goth, fuck, you, nigger, blocked]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nigga i am laying down try na sleep get to bed...</td>\n",
       "      <td>ethnicityandrace</td>\n",
       "      <td>[nigga, i, am, laying, down, try, na, sleep, g...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweets_text              type  \\\n",
       "0  del en as dictator paul makes gay rape jokes a...            gender   \n",
       "1  arabs and muslims do not supporting you do not...          religion   \n",
       "2  is not this a trope in like every teen movie e...            gender   \n",
       "3                  dumb goth fuck you nigger blocked  ethnicityandrace   \n",
       "4  nigga i am laying down try na sleep get to bed...  ethnicityandrace   \n",
       "\n",
       "                                              tokens  ethnicity and race  age  \\\n",
       "0  [del, en, as, dictator, paul, makes, gay, rape...                   0    0   \n",
       "1  [arabs, and, muslims, do, not, supporting, you...                   0    1   \n",
       "2  [is, not, this, a, trope, in, like, every, tee...                   0    3   \n",
       "3           [dumb, goth, fuck, you, nigger, blocked]                   1    1   \n",
       "4  [nigga, i, am, laying, down, try, na, sleep, g...                   3    3   \n",
       "\n",
       "   gender  \n",
       "0       4  \n",
       "1       0  \n",
       "2       3  \n",
       "3       1  \n",
       "4       2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genderDataGlossary = pd.read_csv(r\"C:\\Users\\USER\\Documents\\FinalYearProject\\GenderGlossary.txt\")\n",
    "\n",
    "isGender = []\n",
    "for row in classifyData['tokens']:\n",
    "    temp = 0\n",
    "    for token in row:\n",
    "        for glossary in genderDataGlossary['word']:\n",
    "            if (token == glossary):\n",
    "                temp += 1\n",
    "                break\n",
    "    isGender.append(temp)\n",
    "    \n",
    "classifyData['gender'] = isGender\n",
    "classifyData.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceef1bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets_text</th>\n",
       "      <th>type</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ethnicity and race</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>religion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>del en as dictator paul makes gay rape jokes a...</td>\n",
       "      <td>gender</td>\n",
       "      <td>[del, en, as, dictator, paul, makes, gay, rape...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>arabs and muslims do not supporting you do not...</td>\n",
       "      <td>religion</td>\n",
       "      <td>[arabs, and, muslims, do, not, supporting, you...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is not this a trope in like every teen movie e...</td>\n",
       "      <td>gender</td>\n",
       "      <td>[is, not, this, a, trope, in, like, every, tee...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dumb goth fuck you nigger blocked</td>\n",
       "      <td>ethnicityandrace</td>\n",
       "      <td>[dumb, goth, fuck, you, nigger, blocked]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nigga i am laying down try na sleep get to bed...</td>\n",
       "      <td>ethnicityandrace</td>\n",
       "      <td>[nigga, i, am, laying, down, try, na, sleep, g...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         tweets_text              type  \\\n",
       "0  del en as dictator paul makes gay rape jokes a...            gender   \n",
       "1  arabs and muslims do not supporting you do not...          religion   \n",
       "2  is not this a trope in like every teen movie e...            gender   \n",
       "3                  dumb goth fuck you nigger blocked  ethnicityandrace   \n",
       "4  nigga i am laying down try na sleep get to bed...  ethnicityandrace   \n",
       "\n",
       "                                              tokens  ethnicity and race  age  \\\n",
       "0  [del, en, as, dictator, paul, makes, gay, rape...                   0    0   \n",
       "1  [arabs, and, muslims, do, not, supporting, you...                   0    1   \n",
       "2  [is, not, this, a, trope, in, like, every, tee...                   0    3   \n",
       "3           [dumb, goth, fuck, you, nigger, blocked]                   1    1   \n",
       "4  [nigga, i, am, laying, down, try, na, sleep, g...                   3    3   \n",
       "\n",
       "   gender  religion  \n",
       "0       4         0  \n",
       "1       0         1  \n",
       "2       3         0  \n",
       "3       1         0  \n",
       "4       2         1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "religiousDataGlossary = pd.read_csv(r\"C:\\Users\\USER\\Documents\\FinalYearProject\\ReligionGlossary.txt\")\n",
    "\n",
    "isReligious = []\n",
    "for row in classifyData['tokens']:\n",
    "    temp = 0\n",
    "    for token in row:\n",
    "        for glossary in religiousDataGlossary['word']:\n",
    "            if (token == glossary):\n",
    "                temp += 1\n",
    "                break\n",
    "    isReligious.append(temp)\n",
    "\n",
    "classifyData['religion'] = isReligious\n",
    "classifyData.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db141151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:01<00:00, 21.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  Balanced Accuracy ROC AUC  F1 Score  \\\n",
      "Model                                                                          \n",
      "ExtraTreeClassifier                0.95               0.95    None      0.95   \n",
      "QuadraticDiscriminantAnalysis      0.94               0.94    None      0.94   \n",
      "LogisticRegression                 0.94               0.94    None      0.94   \n",
      "SVC                                0.93               0.93    None      0.93   \n",
      "LinearSVC                          0.93               0.93    None      0.93   \n",
      "LGBMClassifier                     0.93               0.93    None      0.93   \n",
      "CalibratedClassifierCV             0.93               0.93    None      0.93   \n",
      "LabelPropagation                   0.93               0.93    None      0.93   \n",
      "LabelSpreading                     0.93               0.93    None      0.93   \n",
      "NuSVC                              0.93               0.93    None      0.93   \n",
      "DecisionTreeClassifier             0.93               0.93    None      0.93   \n",
      "ExtraTreesClassifier               0.93               0.93    None      0.93   \n",
      "KNeighborsClassifier               0.92               0.92    None      0.92   \n",
      "RandomForestClassifier             0.92               0.92    None      0.92   \n",
      "BaggingClassifier                  0.92               0.92    None      0.92   \n",
      "SGDClassifier                      0.91               0.91    None      0.91   \n",
      "RidgeClassifier                    0.90               0.90    None      0.90   \n",
      "RidgeClassifierCV                  0.90               0.90    None      0.90   \n",
      "LinearDiscriminantAnalysis         0.89               0.89    None      0.89   \n",
      "GaussianNB                         0.88               0.88    None      0.88   \n",
      "Perceptron                         0.87               0.87    None      0.87   \n",
      "NearestCentroid                    0.87               0.87    None      0.87   \n",
      "PassiveAggressiveClassifier        0.87               0.87    None      0.87   \n",
      "BernoulliNB                        0.85               0.85    None      0.85   \n",
      "AdaBoostClassifier                 0.80               0.80    None      0.80   \n",
      "DummyClassifier                    0.25               0.25    None      0.10   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "ExtraTreeClassifier                  0.01  \n",
      "QuadraticDiscriminantAnalysis        0.02  \n",
      "LogisticRegression                   0.03  \n",
      "SVC                                  0.03  \n",
      "LinearSVC                            0.05  \n",
      "LGBMClassifier                       0.29  \n",
      "CalibratedClassifierCV               0.16  \n",
      "LabelPropagation                     0.03  \n",
      "LabelSpreading                       0.02  \n",
      "NuSVC                                0.05  \n",
      "DecisionTreeClassifier               0.02  \n",
      "ExtraTreesClassifier                 0.12  \n",
      "KNeighborsClassifier                 0.01  \n",
      "RandomForestClassifier               0.16  \n",
      "BaggingClassifier                    0.04  \n",
      "SGDClassifier                        0.03  \n",
      "RidgeClassifier                      0.01  \n",
      "RidgeClassifierCV                    0.02  \n",
      "LinearDiscriminantAnalysis           0.02  \n",
      "GaussianNB                           0.02  \n",
      "Perceptron                           0.01  \n",
      "NearestCentroid                      0.01  \n",
      "PassiveAggressiveClassifier          0.03  \n",
      "BernoulliNB                          0.01  \n",
      "AdaBoostClassifier                   0.10  \n",
      "DummyClassifier                      0.01  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predictionDataM2 = classifyData[['age', 'gender', 'religion', 'ethnicity and race']].copy()\n",
    "targetM2 = classifyData['type']\n",
    "\n",
    "#!pip install lazypredict\n",
    "import lazypredict\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "\n",
    "trainData, testData, trainTarget, testTarget = train_test_split(predictionDataM2, targetM2, test_size = 0.15, random_state = 111, stratify = targetM2)\n",
    "models, predictions = clf.fit(trainData, testData, trainTarget, testTarget)\n",
    "print(models)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
